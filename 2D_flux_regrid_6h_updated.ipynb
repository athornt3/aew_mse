{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a135919f-4c24-43ae-b2a0-9aba77b88509",
   "metadata": {},
   "source": [
    "## Code to aggregate ERA5 fluxes over 6 hour intervals\n",
    "\n",
    "\n",
    "Notes\n",
    "\n",
    "- Fuxes are (1) Forecasts made at 6Z and 18Z; and (2) are accumulated over the past hour.\n",
    "\n",
    "    - For any day (D), 6 Z forecast_initial_time, Take forecast hours 1-6: Sum the fluxes and assign to 12 Z  for that day D\n",
    "    - For any day (D), 6 Z forecast_initial_time, Take forecast hours 7-12: Sum the fluxes and assign to 18 Z for that day D\n",
    "    - For any day (D), 18 Z forecast_initial_time, Take forecast hours 1-6: Sum the fluxes and assign to 0 Z  for D+1\n",
    "    - For any day (D), 18 Z forecast_initial_time, Take forecast hours 7-12: Sum the fluxes and assign to 6 Z for D+1\n",
    "  \n",
    "\n",
    "## Note\n",
    "\n",
    "- Fluxes from NCAR RDA are actually coded as 'Watts per m-sq s' which is same as 'Joules per m-sq'\n",
    "\n",
    "\n",
    "### NCSU Large Scale and Tropical Dynamics\n",
    "- A. Aiyyer (Jul 2023)\n",
    "- Sep 6: Updated to divide the 6 hourly accumulated flux by (6*3600) and implemented metpy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ecfee-fe36-4ca2-91ed-85b6d69e5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import date, datetime\n",
    "from numpy import absolute, exp, log\n",
    "\n",
    "# Any import of metpy will activate the accessors\n",
    "from metpy.units import units\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# for regridding\n",
    "import xesmf as xe\n",
    "\n",
    "import metpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a92c8fe-0b62-4973-be4f-2f62461516cf",
   "metadata": {},
   "source": [
    "### Select subset of data\n",
    "Define the specifications for subset of data: Pick latitude and longitude bounds, new grid spacing, and range of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33560a55-b27e-4155-b701-c7896d3677a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid edges\n",
    "latS = -15.\n",
    "latN =  35.\n",
    "lonW = -160.\n",
    "lonE =  50.\n",
    "\n",
    "# grid spacing\n",
    "dlat = 0.5\n",
    "dlon = 0.5\n",
    "\n",
    "# dates\n",
    "year_start = 2022\n",
    "year_end = 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f905fd3b-da78-4803-a124-b48a36bfdd74",
   "metadata": {},
   "source": [
    "### Select variable\n",
    "Pick one of the following 6 fluxes and uncomment the three lines associated with that variable. Keep in mind that the ECMWF defines positive as downward for the indiviudal fluxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f131b-32cd-4fbd-84af-38feca56957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface sensible heat flux\n",
    "#https://codes.ecmwf.int/grib/param-db/?id=146\n",
    "#varId  = '146'\n",
    "#varNam = 'sshf'\n",
    "#variab = 'SSHF'\n",
    "\n",
    "# Surface latent heat flux\n",
    "#https://codes.ecmwf.int/grib/param-db/?id=146\n",
    "#varId  = '147'\n",
    "#varNam = 'slhf'\n",
    "#variab = 'SLHF'    \n",
    "\n",
    "# Surface net short-wave (solar) radiation \n",
    "# https://codes.ecmwf.int/grib/param-db/?id=176\n",
    "#varId  = '176'\n",
    "#varNam = 'ssr'\n",
    "#variab = 'SSR'\n",
    "   \n",
    "# Surface net long-wave (thermal) radiation\n",
    "# https://codes.ecmwf.int/grib/param-db/?id=177\n",
    "#varId  = '177'\n",
    "#varNam = 'str'\n",
    "#variab = 'STR'\n",
    "\n",
    "# Top net short-wave (solar) radiation\n",
    "# https://codes.ecmwf.int/grib/param-db/?id=178\n",
    "varId  = '178'\n",
    "varNam = 'tsr'\n",
    "variab = 'TSR'\n",
    "\n",
    "# Top net long-wave (thermal) radiation\n",
    "# https://codes.ecmwf.int/grib/param-db/?id=179\n",
    "#varId  = '179'\n",
    "#varNam = 'ttr'\n",
    "#variab = 'TTR'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a12657-3d55-446a-af01-812164397c91",
   "metadata": {},
   "source": [
    "### Paths to find and save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "51004b2a-7fcb-4500-ba1d-c7ac43345451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily era5\n",
    "er5_sfc_accu = '/glade/collections/rda/data/ds633.0/e5.oper.fc.sfc.accumu/'\n",
    "\n",
    "# output path for regridded data\n",
    "path_out = '/glade/scratch/athornton/era5_processed_data/2d/2d_updated/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089cad60-05b8-48bc-b79d-1724ca0b9fa8",
   "metadata": {},
   "source": [
    "### Function to select files\n",
    "Implements variable selection and finds file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "da5f274b-c44d-43ad-bbf9-b34a5cb173b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileNames (year):\n",
    "    start = date(year-1,12,1)\n",
    "    end   = date(year,12,1)\n",
    "    dates_list = pd.date_range(start, end, freq='MS')\n",
    "    \n",
    "    fpath = er5_sfc_accu + dates_list.strftime('%Y%m') + '/e5.oper.fc.sfc.accumu.128_'+varId+'_'+varNam  \n",
    "    fils = []\n",
    "    for f in fpath:\n",
    "        fils.append(glob.glob(f + '*nc'))\n",
    "\n",
    "    infiles = [x for l in fils for x in l]\n",
    "    \n",
    "    return infiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624bbbb-3796-45ce-bab1-f818585bb9cd",
   "metadata": {},
   "source": [
    "### Preprocessing before writing\n",
    "Function to implement data and subset specifications while reading in the files. This saves on computing power, since we have to read multiple files in at a time. That way, the accumulation calculations and file writing are the main things taking computing power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9810027-9f59-4ac7-aee5-cbfc908c5b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(ds):\n",
    "    ds = ds.assign_coords(longitude=(((ds.longitude + 180) % 360) - 180))\n",
    "    ds = ds.roll(longitude=int(len(ds['longitude']) / 2), roll_coords=True)\n",
    "    ds = ds.sel(latitude=slice(latN,latS), longitude=slice(lonW,lonE))    \n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21f3316-32f7-4a79-865e-c8714abf71c1",
   "metadata": {},
   "source": [
    "### Function for regridding and calculating aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaaf921e-c7b9-48f3-bdba-cdd68b9ab9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPass = True\n",
    " \n",
    "for year in range (year_start, year_end + 1):\n",
    "    infiles = fileNames (year)\n",
    "    #print(infiles)\n",
    "\n",
    "    ds = xr.open_mfdataset(infiles,  preprocess=preprocess)\n",
    "\n",
    "    # create regriddger only once and reuse it afterward\n",
    "    if (firstPass):\n",
    "        ds_out = xr.Dataset( \n",
    "            {\n",
    "                \"latitude\": ([\"latitude\"], np.arange(latN,latS, -dlat),  {\"units\": \"degrees_north\"}),\n",
    "                \"longitude\": ([\"longitude\"], np.arange(lonW, lonE, dlon), {\"units\": \"degrees_east\"}),\n",
    "\n",
    "            }\n",
    "        )\n",
    "        ds_out.attrs = ds.attrs\n",
    "        regridder = xe.Regridder(ds, ds_out, \"conservative\")\n",
    "        firstPass = False\n",
    "         \n",
    "    dat_out = regridder(ds[variab], keep_attrs=True)  \n",
    "    \n",
    "    \n",
    "    \n",
    "    # now sum over 6 hours for 0,6,12 and 18 Z accumulations\n",
    "    datA=dat_out.sel(forecast_hour=slice(1,6)).sum(dim='forecast_hour', keep_attrs=True)\n",
    "    datB=dat_out.sel(forecast_hour=slice(7,12)).sum(dim='forecast_hour', keep_attrs=True)\n",
    "\n",
    "    \n",
    "    # divide the 6-hourly accumulation by 6*3600 seconds\n",
    "    # note this division removes the attributes from datA and datB. we will add them later\n",
    "    datA = datA.metpy.quantify()/(6*3600*units('s'))  \n",
    "    datB = datB.metpy.quantify()/(6*3600*units('s')) \n",
    "   \n",
    "    \n",
    "    # adjust the time stamps to match the accumulations and rename forecast time to time\n",
    "    datA['forecast_initial_time'] = datA.forecast_initial_time + pd.Timedelta(6, \"h\")\n",
    "    datA = datA.rename({'forecast_initial_time': 'time'})\n",
    "    datB['forecast_initial_time'] = datB.forecast_initial_time + pd.Timedelta(12, \"h\")\n",
    "    datB = datB.rename({'forecast_initial_time': 'time'})\n",
    "\n",
    "    dat_combined = datA.combine_first(datB)\n",
    "    dat_combined = dat_combined.metpy.dequantify()\n",
    "\n",
    "    \n",
    "    # add some attributes\n",
    "    dat_combined.attrs['info'] = '6 hour accumu from 6Z and 18Z forecasts. By NCSU Tropical Dynamics'\n",
    "    dat_combined.attrs['long_name'] = dat_out.attrs['long_name']\n",
    "    dat_combined.attrs['short_name'] = dat_out.attrs['short_name']\n",
    "         \n",
    "    # now loop over each day and write data to netcdf files (4x daily)\n",
    "    for date1 in pd.date_range(str(year) + '-01-01-00', str(year) + '-01-02-00' , freq='D'):\n",
    "        date2 = date1 + pd.Timedelta(18, \"h\")\n",
    "        #print (date1, date2)          \n",
    "        file_out = path_out + varNam+ '_' + date1.strftime(\"%Y%m%d\") + '.nc'\n",
    "        dat_combined.sel(time = slice(date1,date2)).to_netcdf(path=file_out, format='NETCDF4', mode='w')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4865de7-297e-42b0-9aba-441252a2df47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
