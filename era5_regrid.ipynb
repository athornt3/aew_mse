{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8cb38ed-21a3-4bb5-8a90-ae8e8ba32c30",
   "metadata": {},
   "source": [
    "# Extract and Regrid ERA5 data\n",
    "Code to extract era5 data for a specified sub-region and regrid to a coarser grid and also coarser time step\n",
    "\n",
    "\n",
    "- NCSU Large Scale and Tropical Dynamics\n",
    "\n",
    "Versions\n",
    "- A. Aiyyer, Jul 23, 2023\n",
    "- A. Thornton, Sep 14, 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "caa588a0-a87a-4561-9b82-92b0ad628137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "from numpy import absolute, exp, log\n",
    "\n",
    "# Any import of metpy will activate the accessors\n",
    "from metpy.units import units\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# for regridding\n",
    "import xesmf as xe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b625f5-a5b7-48d1-b574-81a139d23cd9",
   "metadata": {},
   "source": [
    "### Paths to find and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c21e1b44-d277-4ee5-9df0-ebcb4b74413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily era5\n",
    "era5_sfc_dir = '/glade/collections/rda/data/ds633.0/e5.oper.an.sfc/'\n",
    "era5_pl_dir  = '/glade/collections/rda/data/ds633.0/e5.oper.an.pl/'\n",
    "\n",
    "\n",
    "# output path to save regridded data\n",
    "path_out = '/glade/scratch/athornton/era5_processed_data/3d/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adaeb40-c4e4-4c4d-a6a8-105c0233c88e",
   "metadata": {},
   "source": [
    "### Select variable\n",
    "Pick one of the following 8 variables, uncomment the three lines representing the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e528260-a793-45b2-817b-1a2a02fd34a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#varId  = '129'\n",
    "#varNam = 'z'\n",
    "#variab = 'Z'  # the variable name in the data file\n",
    "\n",
    "#varId  = '130'\n",
    "#varNam = 't'\n",
    "#variab = 'T'\n",
    "\n",
    "#varId  = '060'\n",
    "#varNam = 'pv'\n",
    "#variab = 'PV'\n",
    "\n",
    "#varId  = '138'\n",
    "#varNam = 'vo'\n",
    "#variab = 'VO'\n",
    "\n",
    "varId  = '133'\n",
    "varNam = 'q'\n",
    "variab = 'Q'\n",
    "\n",
    "#varId  = '135'\n",
    "#varNam = 'w'\n",
    "#variab = 'W'\n",
    "\n",
    "#varId  = '131'\n",
    "#varNam = 'u'\n",
    "#variab = 'U'\n",
    "\n",
    "#varId  = '132'\n",
    "#varNam = 'v'\n",
    "#variab = 'V'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130f8f14-0032-49bd-9edc-fb392cde44b6",
   "metadata": {},
   "source": [
    "### Select subset of data\n",
    "Define the specifications for subset of data: Pick latitude and longitude bounds, new grid spacing, lower and upper bound of levels, and range of dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dba41a2-bd74-41eb-92d1-18967dc3bfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19980401\n",
      "19980430\n"
     ]
    }
   ],
   "source": [
    "# lat/lons\n",
    "latS = -15.\n",
    "latN =  35.\n",
    "lonW = -160.\n",
    "lonE =  50.\n",
    "\n",
    "# grid spacing\n",
    "dlat = 0.5\n",
    "dlon = 0.5\n",
    "\n",
    "# levels\n",
    "level_b = 1000\n",
    "level_t = 100\n",
    "\n",
    "# range of dates\n",
    "year_start  = 1998\n",
    "month_start = 1\n",
    "day_start   = 1\n",
    "\n",
    "year_end  = 2022\n",
    "month_end = 12\n",
    "day_end   = 31\n",
    "\n",
    "date_series = [pd.date_range(date(i,month_start,day_start),date(i,month_end,day_end), freq ='D') for i in range(year_start,year_end+1)]\n",
    "# date_series is a list of lists. Lets unpack it now\n",
    "dates_list = [element for sublist in date_series for element in sublist]\n",
    "\n",
    "print(dates_list[0].strftime(\"%Y%m%d\"))\n",
    "print(dates_list[-1].strftime(\"%Y%m%d\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51d92b5-0af6-40e5-9775-5c0f9f013974",
   "metadata": {},
   "source": [
    "### Function for regridding and applying specifications for subset of data, and downloading and writing new netcdf files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe1c71a8-b169-49ab-a5b5-391f8093f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "firstPass = True\n",
    "\n",
    "for a_date in dates_list:\n",
    "    #print( a_date.strftime('%Y%m%d') )\n",
    "    b_date = a_date + pd.DateOffset(hours=23)\n",
    "    times = [a_date + pd.DateOffset(hour=h) for h in np.arange(0,24,6)]\n",
    "\n",
    "    fname =   a_date.strftime('%Y%m') + '/e5.oper.an.pl.128_'+varId+'_'+varNam+'.ll025sc.' \\\n",
    "    +   a_date.strftime('%Y%m%d')  + '00_' +  a_date.strftime('%Y%m%d') + '23.nc'\n",
    "    \n",
    "    infile = era5_pl_dir + fname    \n",
    "\n",
    "    \n",
    "    ds  = xr.open_dataset(infile)  \n",
    "    \n",
    "    # prepare to roll the longitude from 0 to 360 --> -180 to 180\n",
    "    ds = ds.assign_coords(longitude=(((ds.longitude + 180) % 360) - 180))\n",
    "    \n",
    "    dat = ds[variab].sel(time=times, latitude=slice(latN,latS), level = slice(level_t, level_b))\n",
    "    dat = dat.roll(longitude=int(len(dat['longitude']) / 2), roll_coords=True)\n",
    "    \n",
    "    \n",
    "    # create regriddger only once and reuse it afterward\n",
    "    if (firstPass):\n",
    "        ds_out = xr.Dataset( \n",
    "            {\n",
    "                \"latitude\": ([\"latitude\"], np.arange(latN,latS, -dlat),  {\"units\": \"degrees_north\"}),\n",
    "                \"longitude\": ([\"longitude\"], np.arange(lonW, lonE, dlon), {\"units\": \"degrees_east\"}),\n",
    "\n",
    "            }\n",
    "        )\n",
    "        ds_in = xr.Dataset(\n",
    "            {\n",
    "                \"latitude\": ([\"latitude\"], dat.latitude.values,  {\"units\": \"degrees_north\"}),\n",
    "                \"longitude\": ([\"longitude\"], dat.longitude.values, {\"units\": \"degrees_east\"}),\n",
    "            }\n",
    "        )\n",
    "        regridder = xe.Regridder(ds_in, ds_out, \"conservative\")\n",
    "        firstPass = False\n",
    "        \n",
    "        \n",
    "    # regrid and write to file (4x daily)\n",
    "    dat_out = regridder(dat, keep_attrs=True)    \n",
    "    file_out = path_out + varNam+ '_' + a_date.strftime(\"%Y%m%d\") + '.nc'\n",
    "    dat_out.to_netcdf(path=file_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL 2023b",
   "language": "python",
   "name": "npl-2023b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
